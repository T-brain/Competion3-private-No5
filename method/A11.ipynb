{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import loadtxt\n",
    "from sklearn import cluster, datasets, metrics ,preprocessing\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score,confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def try_par(y_true, y_pred):\n",
    "    minmae=99999\n",
    "    Rnnn=0\n",
    "    for nnn in range(800,1200):\n",
    "        T1 = y_pred*nnn/1000\n",
    "        mae = mean_absolute_error(y_true,T1)\n",
    "        if minmae>mae:\n",
    "            minmae=mae\n",
    "            Rnnn=nnn\n",
    "    return Rnnn/1000\n",
    "\n",
    "def train_model(train_x,train_y,test_x,Re,num_class=3):\n",
    "    params={'booster':'gbtree',\n",
    "        'objective': 'multi:softmax', \n",
    "        'num_class':num_class,\n",
    "        'gamma':0.05,\n",
    "        'max_depth':7,\n",
    "        'subsample':0.5,\n",
    "        'colsample_bytree':0.6,\n",
    "        'silent':1 ,\n",
    "        'eta': 0.07,\n",
    "        'seed':1000,\n",
    "        'nthread':4\n",
    "       }\n",
    "    plst = list(params.items())\n",
    "    num_rounds = 200\n",
    "    offset = int(len(train_x)*0.8)\n",
    "    train_x = train_x.reset_index(drop=True)\n",
    "    train_y = train_y.reset_index(drop=True)\n",
    "    xgtrain = xgb.DMatrix(train_x.loc[:offset,:], label=train_y[:offset+1])\n",
    "    xgval = xgb.DMatrix(train_x.loc[offset:,:], label=train_y[offset:])\n",
    "    watchlist = [(xgtrain, 'train'),(xgval, 'val')]\n",
    "    model = xgb.train(plst, xgtrain, num_rounds, watchlist,early_stopping_rounds=40)\n",
    "\n",
    "    test_x = test_x.reset_index(drop=True)\n",
    "    Re = Re.reset_index(drop=True)\n",
    "    pred1 = model.predict(xgb.DMatrix(Re),ntree_limit=model.best_iteration)\n",
    "    pred2 = model.predict(xgb.DMatrix(test_x),ntree_limit=model.best_iteration)\n",
    "    clear_output()\n",
    "    return pred1,pred2\n",
    "\n",
    "rgb_model = XGBRegressor(\n",
    "                            learning_rate = 0.1,\n",
    "                            n_estimators = 200,\n",
    "                            max_depth= 7,\n",
    "                            objective = 'reg:linear',\n",
    "                            nthread = 4,\n",
    "                            seed=1000\n",
    "                         )\n",
    "def train_model2(train_x,train_y,train_y2,test_x,Mask1,Mask2):\n",
    "    rgb_model.fit(train_x[Mask1],train_y2[Mask1])\n",
    "    T1,T2 = rgb_model.predict(train_x),rgb_model.predict(test_x)\n",
    "    T1[T1<0]=0\n",
    "    T2[T2<0]=0\n",
    "    T3 = train_x['Premium_sum']*T1\n",
    "    T4 = test_x['Premium_sum']*T2\n",
    "    A = try_par(train_y[Mask2],T3[Mask2])\n",
    "    T3,T4=T3*A,T4*A\n",
    "    return T3,T4,A\n",
    "\n",
    "def and2(A,B):\n",
    "    C=A.copy()\n",
    "    C[C]=B\n",
    "    return C\n",
    "\n",
    "def div1(Y,N1,N2):\n",
    "    Z = Y.copy()\n",
    "    A = Y.copy()\n",
    "    Z[A>=N1] = 0\n",
    "    Z[np.logical_and(A<N1,A>N2)] = 1\n",
    "    Z[A<=N2] = 2\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/training_policy_c2.csv')\n",
    "T = pd.read_csv('../data/duplicate_policy.csv',header=None)\n",
    "T = T[0]\n",
    "TF = train['Policy_Number']!=T[0]\n",
    "for i in range(1,len(T)):\n",
    "    TF = np.logical_and(TF,train['Policy_Number']!=T[i])\n",
    "train = train[TF]\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "test = pd.read_csv('../data/testing_policy_c2.csv')\n",
    "train_y = train['Next_Premium'].copy()\n",
    "train_y2 = (train_y/train['Premium_sum'])\n",
    "test_PN = test['Policy_Number']\n",
    "\n",
    "del train['Next_Premium']\n",
    "del test['Next_Premium']\n",
    "del train['Policy_Number']\n",
    "del test['Policy_Number']\n",
    "\n",
    "train_x = train\n",
    "test_x = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2065.9400327689787\n"
     ]
    }
   ],
   "source": [
    "N1,N2= 0.9, 0\n",
    "d00 = div1(train_y2,N1,N2)\n",
    "P00,P01 = train_model(train_x,d00,test_x,train_x)\n",
    "\n",
    "Mask000,Mask001,Mask002 = P00==0,P00==1,P00==2\n",
    "Mask010,Mask011,Mask012 = P01==0,P01==1,P01==2\n",
    "\n",
    "A00,A01=train_x['Premium_sum'] * 1,test_x['Premium_sum'] * 1\n",
    "A00[Mask002]=0\n",
    "A01[Mask012]=0\n",
    "print(mean_absolute_error(train_y,A00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.023 1.005 0.99 1994.3464828726228\n"
     ]
    }
   ],
   "source": [
    "N1,N2= 1.02,0.95\n",
    "d10 = div1(train_y2[Mask000],N1,N2)\n",
    "P10,P11 = train_model(train_x[Mask000],d10,test_x[Mask010],train_x[Mask000])\n",
    "\n",
    "Mask100,Mask101,Mask102 = and2(Mask000,P10==0),and2(Mask000,P10==1),and2(Mask000,P10==2)\n",
    "Mask110,Mask111,Mask112 = and2(Mask010,P11==0),and2(Mask010,P11==1),and2(Mask010,P11==2)\n",
    "\n",
    "Mask1 = np.logical_and(train_y2>0.5,train_y2<1.4)\n",
    "Mask2 = np.logical_and(train_y2>0.7,train_y2<1.05)\n",
    "Mask3 = np.logical_and(train_y2>0.7,train_y2<1.05)\n",
    "T1,T2,A1 = train_model2(train_x,train_y,train_y2,test_x,Mask1,Mask100)\n",
    "T3,T4,A2 = train_model2(train_x,train_y,train_y2,test_x,Mask2,Mask101)\n",
    "T5,T6,A3 = train_model2(train_x,train_y,train_y2,test_x,Mask3,Mask102)\n",
    "\n",
    "A10,A11 = A00.copy(),A01.copy()\n",
    "A10[Mask100]=T1[Mask100]\n",
    "A10[Mask101]=T3[Mask101]\n",
    "A10[Mask102]=T5[Mask102]\n",
    "A11[Mask110]=T2[Mask110]\n",
    "A11[Mask111]=T4[Mask111]\n",
    "A11[Mask112]=T6[Mask112]\n",
    "\n",
    "print(A1,A2,A3,mean_absolute_error(train_y,A10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.015 1.012 0.889 1463.1011926509502\n"
     ]
    }
   ],
   "source": [
    "N1,N2= 0.85,0.7\n",
    "d20 = div1(train_y2[Mask001],N1,N2)\n",
    "P20,P21 = train_model(train_x[Mask001],d20,test_x[Mask011],train_x[Mask001])\n",
    "\n",
    "Mask200,Mask201,Mask202 = and2(Mask001,P20==0),and2(Mask001,P20==1),and2(Mask001,P20==2)\n",
    "Mask210,Mask211,Mask212 = and2(Mask011,P21==0),and2(Mask011,P21==1),and2(Mask011,P21==2)\n",
    "\n",
    "Mask1 = np.logical_and(train_y2>0.6,train_y2<1.05)\n",
    "Mask2 = np.logical_and(train_y2>0.55,train_y2<0.85)\n",
    "Mask3 = np.logical_and(train_y2>0,train_y2<1.25)\n",
    "T1,T2,A1 = train_model2(train_x,train_y,train_y2,test_x,Mask1,Mask200)\n",
    "T3,T4,A2 = train_model2(train_x,train_y,train_y2,test_x,Mask2,Mask201)\n",
    "T5,T6,A3 = train_model2(train_x,train_y,train_y2,test_x,Mask3,Mask202)\n",
    "\n",
    "A20,A21 = A10.copy(),A11.copy()\n",
    "A20[Mask200]=T1[Mask200]\n",
    "A20[Mask201]=T3[Mask201]\n",
    "A20[Mask202]=T5[Mask202]\n",
    "A21[Mask210]=T2[Mask210]\n",
    "A21[Mask211]=T4[Mask211]\n",
    "A21[Mask212]=T6[Mask212]\n",
    "\n",
    "print(A1,A2,A3,mean_absolute_error(train_y,A20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = pd.DataFrame({\"Policy_Number\":test_PN ,\"Next_Premium\":A21})\n",
    "output_csv.to_csv(\"11.csv\", sep=',', index=False, header=True, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
